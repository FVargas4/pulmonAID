{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de Redes Neuronales Neuronales Convolucionales usando PyTorch\n",
    "- Tutorial: [Tutorial profe Cantoral](https://www.youtube.com/watch?v=yUB9JQQVtoU)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones importantes para la red neuronal y el uso de PyTorch:\n",
    "Asegurate de instalar todas las librerias con el comando: <code>pip install torch | pip install torchvision</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '~/Developer/py/pulmonAid'\n",
    "NUM_TRAIN = 50000\n",
    "NUM_VAL = 5000\n",
    "NUM_TEST = 5000\n",
    "MINI_BATCH = 64\n",
    "\n",
    "transform_cifar = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "\"\"\" Train model with dataset \"\"\"\n",
    "\n",
    "# Create training set\n",
    "cifar10_train = datasets.CIFAR10(DATA_PATH, train=True, download=True,\n",
    "                                    transform=transform_cifar)\n",
    "\n",
    "# Load training set to the model using DataLoader object\n",
    "train_loader = DataLoader(cifar10_train, batch_size=MINI_BATCH,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "\"\"\" Create validation set and validate model \"\"\"\n",
    "cifar10_val = datasets.CIFAR10(DATA_PATH, train=False, download=True,\n",
    "                                    transform=transform_cifar)\n",
    "\n",
    "val_loader = DataLoader(cifar10_train, batch_size=MINI_BATCH,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_VAL)))\n",
    "\n",
    "\"\"\" Create test set and test model \"\"\"\n",
    "cifar10_val = datasets.CIFAR10(DATA_PATH, train=False, download=True,\n",
    "                                    transform=transform_cifar)\n",
    "\n",
    "test_loader = DataLoader(cifar10_train, batch_size=MINI_BATCH,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_VAL)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cifar10_grid():\n",
    "    classes = test_loader.dataset.classes\n",
    "    total_samples = 10\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    for label, sample in enumerate(classes):\n",
    "        class_idxs = np.flatnonzero(label == np.array(test_loader.dataset.targets))\n",
    "        sample_idxs = np.random.choice(class_idxs, total_samples, replace=False)\n",
    "        for i, idx in enumerate(sample_idxs):\n",
    "            plt_idx = i*len(classes) + label + 1\n",
    "            plt.subplot(total_samples, len(classes), plt_idx)\n",
    "            plt.imshow(test_loader.dataset.data[idx])\n",
    "            # plt.axis('off')\n",
    "\n",
    "            if i == 0: plt.title(sample)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_cifar10_grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    numCorrect = 0\n",
    "    numTotal = 0\n",
    "    model.eval()\n",
    "    model = model.to(device = device)\n",
    "    with torch.no_grad():\n",
    "        for xi, yi in loader:\n",
    "            xi = xi.to(device=device, dtype= torch.float32)\n",
    "            yi = yi.to(device=device, dtype= torch.long)\n",
    "            scores = model(xi)\n",
    "            _, pred = scores.max(dim=1)\n",
    "            numCorrect += (pred == yi).sum()\n",
    "            numTotal += pred.size(0)\n",
    "        return float(numCorrect)/numTotal\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (xi, yi) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long) \n",
    "            scores = model(xi)\n",
    "            cost = F.cross_entropy(input= scores, target=yi)\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "        acc = accuracy(model, val_loader)\n",
    "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy:{acc}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = 256\n",
    "hidden = 256\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "model1 = nn.Sequential(\n",
    "    nn.Linear(in_features=32*32*3, out_features=hidden1), nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden, out_features=10))\n",
    "optimiser = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "\n",
    "train(model1, optimiser, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "modelCNN1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=channel1, \n",
    "                                    kernel_size=3, padding=1), \n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(in_channels=channel1, out_channels=channel2,\n",
    "                                      kernel_size=3, padding=1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2,2),\n",
    "                            nn.Flatten(),\n",
    "                            nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "                        )\n",
    "optimiser = torch.optim.Adam(modelCNN1.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(modelCNN1, optimiser, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP Advanced Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_k3_p1 = lambda channel1, channel2: nn.Conv2d(channel1, channel2, kernel_size=3, padding=1)\n",
    "\n",
    "class CNNclass(nn.Module):\n",
    "    def __init__(self, in_channel, channel1, channel2):\n",
    "        super().__init__()\n",
    "        self.conv1 = con_k3_p1(in_channel, channel1)\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "\n",
    "        self.conv2 = con_k3_p1(channel1, channel2)\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv2(F.felu(self.conv1(x))))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n",
    "    \n",
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "modelCNN3 = CNNclass(3, channel1, channel2)\n",
    "optimiser = torch.optim.Adam(modelCNN1.parameters(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(modelCNN3, optimiser, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

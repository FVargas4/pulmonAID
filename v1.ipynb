{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de detección de anomalías  v1\n",
    "\n",
    "- Red Neuronal Convolucional que implementa procesamiento de imagenes usando tomografías de pecho para detectar síntomas de neumonía y tumores pulmonares.\n",
    "\n",
    "> Este repositorio no incluye el data set, pues es muy pesado. Aqui puedes encontrar el [dataset de radiografias](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia), descargalo y agregalo al folder.\n",
    "\n",
    "Importaciones necesarias para el modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ferva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:457\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    454\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    455\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[0;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    459\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ver si es posible utilizar los nucleos cuda de los graficos dedicados, si hubiese.\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device: ', {device})\n",
    "\n",
    "accuracyArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = int(input('Are you in the Mac or in the PC? Use 1 to indicate you are using Mac', ))\n",
    "\n",
    "if switch == 1:\n",
    "    \n",
    "    trainPath = '/Users/fervargas/Developer/py/cnn/chest_xray/train'\n",
    "    testPath = '/Users/fervargas/Developer/py/cnn/chest_xray/test'\n",
    "    ValidationPath = '/Users/fervargas/Developer/py/cnn/chest_xray/val' \n",
    "else:\n",
    "    trainPath = \"C:/Users/ferva/Developer/pulmonAID/chest_xray/train\"\n",
    "    testPath = \"C:/Users/ferva/Developer/pulmonAID/chest_xray/test\"\n",
    "    ValidationPath = \"C:/Users/ferva/Developer/pulmonAID/chest_xray/val\"\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([224,224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear data sets para los entrenamientos, la validacion y las pruebas\n",
    "trainDS = datasets.ImageFolder(trainPath, transform=transform)\n",
    "valDS = datasets.ImageFolder(ValidationPath, transform=transform)\n",
    "testDS = datasets.ImageFolder(testPath, transform=transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignar el numero de elementos que se analizaran a la vez (batch) y crear los loaders (objetos que posteriormente se convertira en el modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=batchSize, shuffle=True)\n",
    "valLoader = DataLoader(dataset=valDS, batch_size=batchSize, shuffle=True)\n",
    "testLoader = DataLoader(dataset=testDS, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    plt.show()\n",
    "\n",
    "sample_id = np.random.randint(int(len(testDS)))\n",
    "print(f'La imagen representa: {categorias[testLoader.dataset[sample_id][1]]}')\n",
    "image = testLoader.dataset[sample_id][0]\n",
    "image = (image - image.min()) / (image.max() - image.min())\n",
    "plot_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for (xi, yi) in loader:\n",
    "            xi = xi.to(device=device, dtype = torch.float32)\n",
    "            yi = yi.to(device=device, dtype = torch.long)\n",
    "            scores = model(xi) # mb_size, 10\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "        return float(num_correct)/num_total     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs=100):\n",
    "#     def train(model, optimiser, scheduler = None, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for (xi, yi) in trainLoader:\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = lambda x : model(x)\n",
    "            cost = F.cross_entropy(input= scores(xi), target=yi.squeeze())\n",
    "        \n",
    "            optimiser.zero_grad()           \n",
    "            cost.backward()\n",
    "            optimiser.step()           \n",
    "            \n",
    "        acc = accuracy(model, valLoader)\n",
    "        if epoch%1 == 0:     \n",
    "            print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {acc},')\n",
    "            accuracyArray.append(acc)\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "modelCNN1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,\n",
    "                        padding=1, stride=1, bias=True),\n",
    "                nn.BatchNorm2d(num_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size= (2, 2), stride=(2,2)),\n",
    "            \n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,\n",
    "                        padding=1, stride=1, bias=True),\n",
    "                nn.BatchNorm2d(num_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size= (2, 2), stride=(2,2)),\n",
    "            \n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,\n",
    "                        padding=1, stride=1, bias=True),\n",
    "                nn.BatchNorm2d(num_features=128),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size= (2, 2), stride=(2,2)),\n",
    "            \n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,\n",
    "                        padding=1, stride=1, bias=True),\n",
    "                nn.BatchNorm2d(num_features=128),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size= (2, 2), stride=(2,2)),\n",
    "            \n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features = 14*14*128, out_features = 2, bias=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_classes = 2\n",
    "# lr = 0.000031\n",
    "lr = 0.00001\n",
    "optimizer = optim.Adam(params = modelCNN1.parameters(), lr= lr)\n",
    "train(modelCNN1, optimizer, epochs)\n",
    "# acc = accuracy(modelCNN1, valLoader)\n",
    "acc = accuracy(modelCNN1, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = float(0.0)\n",
    "for item in accuracyArray:\n",
    "    aux += item\n",
    "\n",
    "print(aux / len(accuracyArray))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
